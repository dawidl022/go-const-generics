\section{Implementation}
\label{ch:interpter-impl}

As part of this work two interpreters were implemented, one for FGA and one for
FGGA. In addition, a monomorphiser was implemented translating FGGA to Go. The
output of the monomorphiser is a valid subset of FGGA, so it can be interpreted
by the FGGA interpreter as well as compiled by the official Go compiler.

One of the aims of building the interpreters, was to test the formal syntax,
reduction and typing rules defined in sections \ref{ch:fg} and \ref{ch:fgg}, and
amend them when inconsistencies or issue arose. The aim of the monomorphiser was
to prototype a translation from const-generic Go code, to regular Go code, which
is a useful first step to actually introducing this feature into the mainstream
compiler. One could also extend the monomorphiser to support a proper superset
of Go, which would allow developers to use generically sized arrays in their
source code, and use the monomorphiser as the first step of the compilation
process, the result of which could be fed directly into the Go compiler.

A similar set of programs were found in the set of artifacts in Featherweight Go
\autocite{fg} - interpreters for the two languages formalised, and a
monomorphiser translating generics (the feature introduced by Featherweight Go)
into code that the official Go compiler at the time could handle.

\subsection{Libraries and patterns}

ANLTR\footnote{\href{https://www.antlr.org/}{ANLTR: https://www.antlr.org/}} was
used to generate the parser, and the interpreters and monomorphiser were
implemented in Go itself.

The visitor pattern was heavily employed throughout the code for operations
including building the abstract syntax tree (AST), preprocessing to remove
ambiguity resulting from the grammar (as discussed in section
\ref{sec:fgg-syntax}), type checking, reduction, monomorphisation, and various
other auxiliary operations. The pattern makes it easy to recursively traverse
the AST and apply the desired operation.

% The operation is applied at certain base cases, and the visitor can keep track
% of the parent's context, which is passed along (with potentially more data) at
% each level of recursion

It allows for the separation of concerns, i.e. each operation can live in its
own package. Simply defining methods on the AST would force all operations to be
defined in a single package (in Go, methods on a type can only be defined in the
same package the type is declared), limiting the code organisation flexibility.

% It is extensible, e.g. multiple different operations can implement the same
% visitor interface, provided the return types align. Because often they don't
% align (e.g. some operations can error, while other cannot), in practice
% multiple visitor interface variants were created. Additionally, in some cases,
% it was only desired to traverse a subtree, hence not all ast node types needed
% to be visited, and so special purpose subtree visitors were also created.

% The downside of the visitor pattern is that it produces a bit of boilerplate
% code, however, IDEs make it easy to generate, and we can shove it all away
% into ``biolerplate.go'' and only worry about the actual functionality.

% Another downside is the proliferation of type casts (assertions).

\subsection{Testing}

The programs were written using test-driven development (TDD), where the test
inputs for most components were small example programs, aimed at testing a
single feature or case.

Since under TDD no feature may be implemented without an accompanying test, all
developed features are covered by tests. TDD allows for fearless refactoring,
since all features are fully covered by tests. Using example program as test
inputs allows for arbitrary refactoring of the implementation. During
development, such a major refactoring was undertaken - moving the type parameter
substitution (the need for which arising from the grammar ambiguity) from an ad
hoc basis to a separate preprocessing step (i.e. a separate pass of the AST)
before any type checking started.

A core part of the implementation was coming up with edge cases, writing tests
to check how the interpreter behaved, and if necessary updating both the formal
rules and implementation to cover the edge case. E.g in FGGA the $\notref$
auxiliary had to be updated to instantiate the type literals it recursively
checks, as a result of the described process.

% projects/go-generic-array-sizes/interpreters/fgg/typecheck/testdata/self_ref/self_ref_in_type_arg

In fact, following this process, at least once bug in the official Go compiler
(as of Go 1.22) was caught, causing the compiler to either crash due to stack
overflow, or incorrectly type check a program (behaviour dependent on input)
The two errors were subsequently reported as issues on Go's GitHub repo, where
exact details can be
found\footnote{\href{https://github.com/golang/go/issues/65711}{issue 65711} and
    \href{https://github.com/golang/go/issues/65714}{65714}}.

% projects/go-generic-array-sizes/interpreters/fgg/typecheck/testdata/self_ref/self_ref_indirect/self_ref_indirect.go

% Some snippet of testing (TestMonomorphise_givenStructFieldOfConstGenericArrayType):
% Diff:
% --- Expected
% +++ Actual
% @@ -8,3 +8,3 @@
% type Foo__2 struct {
% -	x Arr__2[int]
% +	x Arr[N, int]
% }

% TODO include table with test statistics (i.e. number of tests for each
% component of relevance and maybe code coverage). Make this table generated
% automatically from running test suites.
%
% 100% code coverage does not occur due to some parts of the code being
% unreachable, yet necessary due to the language's type system.
